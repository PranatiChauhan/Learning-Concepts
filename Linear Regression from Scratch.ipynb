{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(x, w):\n",
    "    return np.dot(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def update_weights(x_train, y_train, weights, learning_rate):\n",
    "    #get predictions first\n",
    "    predictions = predict(x_train, weights)\n",
    "    delta_weight = (np.dot(x_train.T, y_train - predictions)) / x_train.shape[0]\n",
    "    weights += learning_rate * delta_weight\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(x, y, weights):\n",
    "    predictions = predict(x, weights)\n",
    "    error = y - predictions\n",
    "    return np.mean((error ** 2) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_lr(x_train, y_train, max_iter, learning_rate, fit_intercept = False):\n",
    "    if fit_intercept:\n",
    "        x0 = np.ones((x_train.shape[0], 1))\n",
    "        x_train = np.hstack((x0, x_train))\n",
    "\n",
    "    #create weights matrix\n",
    "    weights = np.zeros(x_train.shape[1])\n",
    "\n",
    "    #iterate through the observations and update weights\n",
    "    for iteration in range(max_iter):\n",
    "        update_weights(x_train, y_train, weights, learning_rate)\n",
    "        #display cost once in 100 iterations\n",
    "        if iteration % 100 == 0:\n",
    "            print(f\"Cost: {compute_cost(x_train, y_train, weights):.2f}\")\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def y_predict(x, weights):\n",
    "    if x.shape[1] == weights.shape[0] - 1:\n",
    "        intercept = np.ones((x.shape[0], 1))\n",
    "        x = np.hstack((intercept, x) )\n",
    "    return predict(x, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Let us test it on the diabetes dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()\n",
    "x = data.data\n",
    "y = data.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 3023.83\n",
      "Cost: 2110.61\n",
      "Cost: 1858.50\n",
      "Cost: 1753.96\n",
      "Cost: 1697.64\n",
      "Cost: 1663.90\n",
      "Cost: 1642.87\n",
      "Cost: 1629.49\n",
      "Cost: 1620.85\n",
      "Cost: 1615.17\n",
      "Cost: 1611.38\n",
      "Cost: 1608.81\n",
      "Cost: 1607.02\n",
      "Cost: 1605.75\n",
      "Cost: 1604.82\n",
      "Cost: 1604.12\n",
      "Cost: 1603.58\n",
      "Cost: 1603.16\n",
      "Cost: 1602.81\n",
      "Cost: 1602.52\n",
      "Cost: 1602.26\n",
      "Cost: 1602.04\n",
      "Cost: 1601.84\n",
      "Cost: 1601.65\n",
      "Cost: 1601.48\n",
      "Cost: 1601.32\n",
      "Cost: 1601.17\n",
      "Cost: 1601.03\n",
      "Cost: 1600.88\n",
      "Cost: 1600.75\n",
      "Cost: 1600.62\n",
      "Cost: 1600.49\n",
      "Cost: 1600.36\n",
      "Cost: 1600.24\n",
      "Cost: 1600.11\n",
      "Cost: 1599.99\n",
      "Cost: 1599.88\n",
      "Cost: 1599.76\n",
      "Cost: 1599.64\n",
      "Cost: 1599.53\n",
      "Cost: 1599.42\n",
      "Cost: 1599.31\n",
      "Cost: 1599.20\n",
      "Cost: 1599.09\n",
      "Cost: 1598.98\n",
      "Cost: 1598.87\n",
      "Cost: 1598.77\n",
      "Cost: 1598.66\n",
      "Cost: 1598.56\n",
      "Cost: 1598.46\n",
      "Cost: 1598.36\n",
      "Cost: 1598.26\n",
      "Cost: 1598.16\n",
      "Cost: 1598.06\n",
      "Cost: 1597.96\n",
      "Cost: 1597.86\n",
      "Cost: 1597.76\n",
      "Cost: 1597.67\n",
      "Cost: 1597.57\n",
      "Cost: 1597.48\n",
      "Cost: 1597.39\n",
      "Cost: 1597.29\n",
      "Cost: 1597.20\n",
      "Cost: 1597.11\n",
      "Cost: 1597.02\n",
      "Cost: 1596.93\n",
      "Cost: 1596.84\n",
      "Cost: 1596.75\n",
      "Cost: 1596.66\n",
      "Cost: 1596.57\n",
      "Cost: 1596.49\n",
      "Cost: 1596.40\n",
      "Cost: 1596.31\n",
      "Cost: 1596.23\n",
      "Cost: 1596.14\n",
      "Cost: 1596.06\n",
      "Cost: 1595.97\n",
      "Cost: 1595.89\n",
      "Cost: 1595.81\n",
      "Cost: 1595.73\n",
      "Cost: 1595.64\n",
      "Cost: 1595.56\n",
      "Cost: 1595.48\n",
      "Cost: 1595.40\n",
      "Cost: 1595.32\n",
      "Cost: 1595.24\n",
      "Cost: 1595.16\n",
      "Cost: 1595.08\n",
      "Cost: 1595.01\n",
      "Cost: 1594.93\n",
      "Cost: 1594.85\n",
      "Cost: 1594.77\n",
      "Cost: 1594.70\n",
      "Cost: 1594.62\n",
      "Cost: 1594.55\n",
      "Cost: 1594.47\n",
      "Cost: 1594.40\n",
      "Cost: 1594.32\n",
      "Cost: 1594.25\n",
      "Cost: 1594.17\n",
      "Cost: 1594.10\n",
      "Cost: 1594.03\n",
      "Cost: 1593.95\n",
      "Cost: 1593.88\n",
      "Cost: 1593.81\n",
      "Cost: 1593.74\n",
      "Cost: 1593.67\n",
      "Cost: 1593.60\n",
      "Cost: 1593.53\n",
      "Cost: 1593.46\n",
      "Cost: 1593.39\n",
      "Cost: 1593.32\n",
      "Cost: 1593.25\n",
      "Cost: 1593.18\n",
      "Cost: 1593.11\n",
      "Cost: 1593.04\n",
      "Cost: 1592.97\n",
      "Cost: 1592.91\n",
      "Cost: 1592.84\n",
      "Cost: 1592.77\n",
      "Cost: 1592.70\n",
      "Cost: 1592.64\n",
      "Cost: 1592.57\n",
      "Cost: 1592.51\n",
      "Cost: 1592.44\n",
      "Cost: 1592.38\n",
      "Cost: 1592.31\n",
      "Cost: 1592.25\n",
      "Cost: 1592.18\n",
      "Cost: 1592.12\n",
      "Cost: 1592.05\n",
      "Cost: 1591.99\n",
      "Cost: 1591.93\n",
      "Cost: 1591.87\n",
      "Cost: 1591.80\n",
      "Cost: 1591.74\n",
      "Cost: 1591.68\n",
      "Cost: 1591.62\n",
      "Cost: 1591.55\n",
      "Cost: 1591.49\n",
      "Cost: 1591.43\n",
      "Cost: 1591.37\n",
      "Cost: 1591.31\n",
      "Cost: 1591.25\n",
      "Cost: 1591.19\n",
      "Cost: 1591.13\n",
      "Cost: 1591.07\n",
      "Cost: 1591.01\n",
      "Cost: 1590.95\n",
      "Cost: 1590.89\n",
      "Cost: 1590.84\n",
      "Cost: 1590.78\n",
      "Cost: 1590.72\n",
      "Cost: 1590.66\n",
      "Cost: 1590.60\n",
      "Cost: 1590.55\n",
      "Cost: 1590.49\n",
      "Cost: 1590.43\n",
      "Cost: 1590.38\n",
      "Cost: 1590.32\n",
      "Cost: 1590.26\n",
      "Cost: 1590.21\n",
      "Cost: 1590.15\n",
      "Cost: 1590.10\n",
      "Cost: 1590.04\n",
      "Cost: 1589.99\n",
      "Cost: 1589.93\n",
      "Cost: 1589.88\n",
      "Cost: 1589.82\n",
      "Cost: 1589.77\n",
      "Cost: 1589.72\n",
      "Cost: 1589.66\n",
      "Cost: 1589.61\n",
      "Cost: 1589.56\n",
      "Cost: 1589.50\n",
      "Cost: 1589.45\n",
      "Cost: 1589.40\n",
      "Cost: 1589.35\n",
      "Cost: 1589.29\n",
      "Cost: 1589.24\n",
      "Cost: 1589.19\n",
      "Cost: 1589.14\n",
      "Cost: 1589.09\n",
      "Cost: 1589.04\n",
      "Cost: 1588.99\n",
      "Cost: 1588.94\n",
      "Cost: 1588.88\n",
      "Cost: 1588.83\n",
      "Cost: 1588.78\n",
      "Cost: 1588.73\n",
      "Cost: 1588.68\n",
      "Cost: 1588.64\n",
      "Cost: 1588.59\n",
      "Cost: 1588.54\n",
      "Cost: 1588.49\n",
      "Cost: 1588.44\n",
      "Cost: 1588.39\n",
      "Cost: 1588.34\n",
      "Cost: 1588.30\n",
      "Cost: 1588.25\n"
     ]
    }
   ],
   "source": [
    "weights = train_lr(x_train,y_train, max_iter = 20000, learning_rate = 1, fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = y_predict(x_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6022765141795811\n",
      "2197.928491521614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(r2_score(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
       "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
       "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, -0.00567042, -0.04559945,\n",
       "        -0.03419447, -0.03235593, -0.00259226,  0.00286131, -0.02593034],\n",
       "       [-0.08906294, -0.04464164, -0.01159501, -0.03665608,  0.01219057,\n",
       "         0.02499059, -0.03603757,  0.03430886,  0.02268774, -0.00936191],\n",
       "       [ 0.00538306, -0.04464164, -0.03638469,  0.02187239,  0.00393485,\n",
       "         0.01559614,  0.00814208, -0.00259226, -0.03198764, -0.04664087]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
